{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1+1 Evolutionary Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases how to use the built-in 1+1 Evolutionary Algorithm (EA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using EvoLP\n",
    "using OrderedCollections\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use the **OneMax** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "The \\textbf{OneMax} function returns the sum of the individual. For an individual of length $n$, maximum is achieved with $n$ ones.\n",
       "\n",
       "$$\\text{OneMax}(\\mathbf{x}) = \\sum_{i=1}^n x_i$$\n"
      ],
      "text/markdown": [
       "The **OneMax** function returns the sum of the individual. For an individual of length $n$, maximum is achieved with $n$ ones.\n",
       "\n",
       "$$\n",
       "\\text{OneMax}(\\mathbf{x}) = \\sum_{i=1}^n x_i\n",
       "$$\n"
      ],
      "text/plain": [
       "  The \u001b[1mOneMax\u001b[22m function returns the sum of the individual. For an individual of\n",
       "  length \u001b[35mn\u001b[39m, maximum is achieved with \u001b[35mn\u001b[39m ones.\n",
       "\n",
       "\u001b[35m  \\text{OneMax}(\\mathbf{x}) = \\sum_{i=1}^n x_i\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@doc onemax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an EA we use vectors as _individuals_. The <span style=\"color:magenta\">1</span>+<span style=\"color:blue\">1</span> EA features <span style=\"color:magenta\">1 _parent_</span> and <span style=\"color:blue\">1 _offspring_</span> each iteration.\n",
    "\n",
    "Let's start creating the first individual. We can use the _binary generator_ included in EvoLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "binary_vector_pop(n, l; rng=Random.GLOBAL_RNG)\n",
       "\\end{verbatim}\n",
       "Generate a population of \\texttt{n} vector binary individuals, each of length \\texttt{l}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> using EvoLP\n",
       "\n",
       "julia> binary_vector_pop(2, 5)\n",
       "2-element Vector{BitVector}:\n",
       " [1, 0, 1, 1, 0]\n",
       " [0, 1, 0, 0, 0]\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "binary_vector_pop(n, l; rng=Random.GLOBAL_RNG)\n",
       "```\n",
       "\n",
       "Generate a population of `n` vector binary individuals, each of length `l`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```julia\n",
       "julia> using EvoLP\n",
       "\n",
       "julia> binary_vector_pop(2, 5)\n",
       "2-element Vector{BitVector}:\n",
       " [1, 0, 1, 1, 0]\n",
       " [0, 1, 0, 0, 0]\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  binary_vector_pop(n, l; rng=Random.GLOBAL_RNG)\u001b[39m\n",
       "\n",
       "  Generate a population of \u001b[36mn\u001b[39m vector binary individuals, each of length \u001b[36ml\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> using EvoLP\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> binary_vector_pop(2, 5)\u001b[39m\n",
       "\u001b[36m  2-element Vector{BitVector}:\u001b[39m\n",
       "\u001b[36m   [1, 0, 1, 1, 0]\u001b[39m\n",
       "\u001b[36m   [0, 1, 0, 0, 0]\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@doc binary_vector_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that the return value of a _population_ is a list, so we want the first (and only) element inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element BitVector:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind_size = 15\n",
    "firstborn = binary_vector_pop(1, ind_size)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 1+1 EA works on a single individual, we only have the _mutation step_. We can set up the appropriate mtuation operator: `BitwiseMutation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Bitwise mutation with probability \\texttt{λ} of flipping each bit.\n",
       "\n"
      ],
      "text/markdown": [
       "Bitwise mutation with probability `λ` of flipping each bit.\n"
      ],
      "text/plain": [
       "  Bitwise mutation with probability \u001b[36mλ\u001b[39m of flipping each bit."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@doc BitwiseMutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitwiseMutation(0.06666666666666667)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mut = BitwiseMutation(1/ind_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to the fitness function. EvoLP is built for _minimisation_, so we need to optimise for the _negative_ of **OneMax**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(x) = -onemax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `Logbook` to record the fitness value on each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Logbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"fit\" => g), NamedTuple{(:fit,)}[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "statnames = [\"fit\"]\n",
    "g(x) = x[1]  # trick to get the fitness\n",
    "thedict = LittleDict(statnames, [g])\n",
    "logbook = Logbook(thedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to use the `oneplusone` built-in algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "oneplusone(f, ind, k_max, M)\n",
       "oneplusone(logger::Logbook, f, ind, k_max, M)\n",
       "\\end{verbatim}\n",
       "1+1 Evolutionary Algorithm.\n",
       "\n",
       "\\section{Arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{f::Function}: objective function to \\textbf{minimise}.\n",
       "\n",
       "\n",
       "\\item \\texttt{ind::AbstractVector}: individual to start the evolution.\n",
       "\n",
       "\n",
       "\\item \\texttt{k\\_max::Integer}: number of iterations.\n",
       "\n",
       "\n",
       "\\item \\texttt{M::MutationMethod}: one of the available \\href{@ref}{\\texttt{MutationMethod}}.\n",
       "\n",
       "\\end{itemize}\n",
       "Returns a \\href{@ref}{\\texttt{Result}}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "oneplusone(f, ind, k_max, M)\n",
       "oneplusone(logger::Logbook, f, ind, k_max, M)\n",
       "```\n",
       "\n",
       "1+1 Evolutionary Algorithm.\n",
       "\n",
       "# Arguments\n",
       "\n",
       "  * `f::Function`: objective function to **minimise**.\n",
       "  * `ind::AbstractVector`: individual to start the evolution.\n",
       "  * `k_max::Integer`: number of iterations.\n",
       "  * `M::MutationMethod`: one of the available [`MutationMethod`](@ref).\n",
       "\n",
       "Returns a [`Result`](@ref).\n"
      ],
      "text/plain": [
       "\u001b[36m  oneplusone(f, ind, k_max, M)\u001b[39m\n",
       "\u001b[36m  oneplusone(logger::Logbook, f, ind, k_max, M)\u001b[39m\n",
       "\n",
       "  1+1 Evolutionary Algorithm.\n",
       "\n",
       "\u001b[1m  Arguments\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •  \u001b[36mf::Function\u001b[39m: objective function to \u001b[1mminimise\u001b[22m.\n",
       "\n",
       "    •  \u001b[36mind::AbstractVector\u001b[39m: individual to start the evolution.\n",
       "\n",
       "    •  \u001b[36mk_max::Integer\u001b[39m: number of iterations.\n",
       "\n",
       "    •  \u001b[36mM::MutationMethod\u001b[39m: one of the available \u001b[36mMutationMethod\u001b[39m.\n",
       "\n",
       "  Returns a \u001b[36mResult\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@doc oneplusone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = oneplusone(logbook, f, firstborn, 50, Mut);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output was suppressed so that we can analyse each part of the result separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum(result) = -14\n",
      "optimizer(result) = Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "iterations(result) = 50\n",
      "f_calls(result) = 100\n"
     ]
    }
   ],
   "source": [
    "@show optimum(result)\n",
    "\n",
    "@show optimizer(result)\n",
    "\n",
    "@show iterations(result)\n",
    "\n",
    "@show f_calls(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the logbook records (or in this case, the first 10) and see how the statistics changed throughout the run (although in this case we just logged the fitness):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first(logbook.records, 10) = NamedTuple{(:fit,)}[(fit = -8,), (fit = -9,), (fit = -9,), (fit = -9,), (fit = -9,), (fit = -9,), (fit = -10,), (fit = -10,), (fit = -10,), (fit = -10,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Vector{NamedTuple{(:fit,)}}:\n",
       " (fit = -8,)\n",
       " (fit = -9,)\n",
       " (fit = -9,)\n",
       " (fit = -9,)\n",
       " (fit = -9,)\n",
       " (fit = -9,)\n",
       " (fit = -10,)\n",
       " (fit = -10,)\n",
       " (fit = -10,)\n",
       " (fit = -10,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show first(logbook.records, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
